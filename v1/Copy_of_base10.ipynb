{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BuGYJn3X7RV",
        "outputId": "2c91e17d-cf37-44c9-8550-b8c2f0fe3eaf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\POOJYANTH REDDY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "C:\\Users\\POOJYANTH REDDY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.12.0 and strictly below 2.15.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.11.1 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import ResNet152\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.losses import categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JnkM41BgRx0",
        "outputId": "52e3555d-9083-432a-f9ac-c0ca8f2828d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Z78QLGsgX7Re"
      },
      "outputs": [],
      "source": [
        "def load_and_process_images(path_dir, class_labels, target_num_images):\n",
        "    images = []\n",
        "    labels = []\n",
        "    min_images = 99999999\n",
        "    class_images = {}\n",
        "\n",
        "    for label, class_name in enumerate(class_labels):\n",
        "        class_dir = os.path.join(path_dir, class_name)\n",
        "        class_images[class_name] = []\n",
        "\n",
        "        if not os.path.exists(class_dir):\n",
        "            print(f\"Directory '{class_name}' not found in '{path_dir}'. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        for jpg in os.listdir(class_dir):\n",
        "            image_path = os.path.join(class_dir, jpg)\n",
        "            image_high_resolution = cv2.imread(image_path)\n",
        "\n",
        "            if image_high_resolution is None:\n",
        "                print(f\"Could not read image '{jpg}' in '{class_name}' directory. Skipping...\")\n",
        "                continue\n",
        "\n",
        "            # print(f\"Reading image '{jpg}' in '{class_name}' directory...\")\n",
        "            image_change_color = cv2.cvtColor(image_high_resolution, cv2.COLOR_BGR2RGB)\n",
        "            image_low_resolution = cv2.resize(image_change_color, (256, 256))\n",
        "            class_images[class_name].append(image_low_resolution)\n",
        "            min_images = min(min_images, len(class_images[class_name]))\n",
        "        print(f\"Class '{class_name}' has {len(class_images[class_name])} images.\")\n",
        "\n",
        "\n",
        "    for class_name, images_list in class_images.items():\n",
        "            images.extend(images_list)\n",
        "            labels.extend([class_name] * len(images_list))\n",
        "\n",
        "    return np.asarray(images), np.asarray(labels), min_images, class_images\n",
        "\n",
        "\n",
        "\n",
        "dataset_directory = './Datasets/DataImages/'\n",
        "class_labels = ['Catla', 'Cyprinus carpio', 'Grass Carp', 'Mori', 'Rohu', 'Silver']\n",
        "target_num_images = 50\n",
        "\n",
        "# images, labels, min_images, class_images = load_and_process_images(dataset_directory, class_labels, target_num_images)\n",
        "\n",
        "# print(f\"Number of images: {len(images)}\")\n",
        "# print(f\"Number of labels: {len(labels)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0ecF-7Az0tw",
        "outputId": "c44ae5ed-0e8e-48c0-956c-3a9946664bf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 'Catla' has 20 images.\n",
            "Class 'Cyprinus carpio' has 50 images.\n",
            "Class 'Grass Carp' has 11 images.\n",
            "Class 'Mori' has 70 images.\n",
            "Class 'Rohu' has 73 images.\n",
            "Class 'Silver' has 47 images.\n"
          ]
        }
      ],
      "source": [
        "# Constants\n",
        "BATCH_SIZE = 64\n",
        "TAU = 0.1\n",
        "PROJECTION_DIM = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "# Image shape\n",
        "IMG_SHAPE = (256, 256, 3)\n",
        "\n",
        "# Load and preprocess data\n",
        "images, labels, _, _ = load_and_process_images(dataset_directory, class_labels, target_num_images)\n",
        "\n",
        "# Split data into train and test sets\n",
        "images_train, images_test, labels_train, labels_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "p_icol16o3PG"
      },
      "outputs": [],
      "source": [
        "# Split the data into train and test sets\n",
        "split_ratio = 0.8  # 80% train, 20% test\n",
        "num_samples = len(images)\n",
        "split_index = int(split_ratio * num_samples)\n",
        "\n",
        "train_images, test_images = images[:split_index], images[split_index:]\n",
        "train_labels, test_labels = labels[:split_index], labels[split_index:]\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(buffer_size=num_samples).batch(BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer 'model_9' (type Functional).\n\nInput 0 of layer \"model_8\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(64, 256, 256, 3)\n\nCall arguments received by layer 'model_9' (type Functional):\n  • inputs=tf.Tensor(shape=(64, 256, 256, 3), dtype=uint8)\n  • training=True\n  • mask=None",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[13], line 73\u001b[0m\n\u001b[0;32m     70\u001b[0m simclr_model \u001b[38;5;241m=\u001b[39m get_simclr_model(encoder)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Assuming 'dataset' is your training dataset\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m \u001b[43mtrain_simclr\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimclr_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[13], line 53\u001b[0m, in \u001b[0;36mtrain_simclr\u001b[1;34m(simclr_model, dataset, epochs, batch_size)\u001b[0m\n\u001b[0;32m     50\u001b[0m images_j \u001b[38;5;241m=\u001b[39m data_augmentation(batch[\u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Assuming the image data is in the first element of the tuple\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m---> 53\u001b[0m     z_i, z_j \u001b[38;5;241m=\u001b[39m \u001b[43msimclr_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m# Create negative pairs (z_i, z_k)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     shuffled_indices \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrange(tf\u001b[38;5;241m.\u001b[39mshape(images_i)[\u001b[38;5;241m0\u001b[39m])\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\input_spec.py:295\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m--> 295\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    296\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    297\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    299\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisplay_shape(x\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    300\u001b[0m         )\n",
            "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer 'model_9' (type Functional).\n\nInput 0 of layer \"model_8\" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(64, 256, 256, 3)\n\nCall arguments received by layer 'model_9' (type Functional):\n  • inputs=tf.Tensor(shape=(64, 256, 256, 3), dtype=uint8)\n  • training=True\n  • mask=None"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "# Define the encoder architecture\n",
        "def get_encoder(input_shape, projection_dim=128):\n",
        "    base_model = tf.keras.applications.ResNet50(weights=None, include_top=False, input_shape=input_shape)\n",
        "    base_model.trainable = True\n",
        "\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    x = base_model(inputs, training=True)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.Dense(projection_dim, activation='relu')(x)\n",
        "    x = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))(x)\n",
        "\n",
        "    return Model(inputs, x)\n",
        "\n",
        "# Define the contrastive loss function\n",
        "def contrastive_loss(z_i, z_j, temperature=0.1):\n",
        "    sim_ij = tf.reduce_sum(tf.multiply(z_i, z_j), axis=-1)\n",
        "    exp_sim_ij = tf.exp(sim_ij / temperature)\n",
        "    numerator = tf.linalg.diag_part(exp_sim_ij)\n",
        "    denominator = tf.reduce_sum(exp_sim_ij, axis=-1)\n",
        "    loss = -tf.math.log(numerator / denominator)\n",
        "    return loss\n",
        "\n",
        "# Create the SimCLR model\n",
        "def get_simclr_model(encoder, temperature=0.1):\n",
        "    inputs = tf.keras.Input(shape=(None, None, 3))\n",
        "    x_i = encoder(inputs)\n",
        "    x_j = encoder(inputs)\n",
        "\n",
        "    simclr_model = Model(inputs, [x_i, x_j])\n",
        "    simclr_model.compile(optimizer=Adam(), loss=lambda _, y_pred: contrastive_loss(*y_pred, temperature=temperature))\n",
        "\n",
        "    return simclr_model\n",
        "\n",
        "# Dummy data augmentation function\n",
        "def data_augmentation(image):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    return image\n",
        "\n",
        "# SimCLR training loop\n",
        "def train_simclr(simclr_model, dataset, epochs=10, batch_size=64):\n",
        "    for epoch in range(epochs):\n",
        "        for batch in dataset:\n",
        "            images_i = data_augmentation(batch[0])  # Assuming the image data is in the first element of the tuple\n",
        "            images_j = data_augmentation(batch[0])  # Assuming the image data is in the first element of the tuple\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                z_i, z_j = simclr_model(images_i, training=True)\n",
        "\n",
        "                # Create negative pairs (z_i, z_k)\n",
        "                shuffled_indices = tf.range(tf.shape(images_i)[0])\n",
        "                shuffled_indices = tf.random.shuffle(shuffled_indices)\n",
        "                images_k = tf.gather(images_i, shuffled_indices)\n",
        "                z_k = simclr_model(images_k, training=True)[0]\n",
        "\n",
        "                # Calculate contrastive loss\n",
        "                loss = contrastive_loss(z_i, z_j) + contrastive_loss(z_i, z_k)\n",
        "\n",
        "            gradients = tape.gradient(loss, simclr_model.trainable_variables)\n",
        "            simclr_model.optimizer.apply_gradients(zip(gradients, simclr_model.trainable_variables))\n",
        "\n",
        "# Example usage\n",
        "input_shape = (224, 224, 3)\n",
        "encoder = get_encoder(input_shape)\n",
        "simclr_model = get_simclr_model(encoder)\n",
        "\n",
        "# Assuming 'dataset' is your training dataset\n",
        "train_simclr(simclr_model, train_dataset, epochs=10, batch_size=64)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
