{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5ooGIYTprU6S"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from itertools import combinations\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55DH53Omt7NS",
        "outputId": "b209e304-7e96-41b0-96d6-dd530d24a997"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6X8UhT9tPee",
        "outputId": "00da9bb4-e188-4ef3-86a9-7f24bf5a48f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 'Catla' has 20 images.\n",
            "Class 'Cyprinus carpio' has 50 images.\n",
            "Class 'Grass Carp' has 11 images.\n",
            "Class 'Mori' has 70 images.\n",
            "Class 'Rohu' has 73 images.\n",
            "Class 'Silver' has 47 images.\n"
          ]
        }
      ],
      "source": [
        "def load_and_process_images(path_dir, class_labels, target_num_images):\n",
        "    images = []\n",
        "    labels = []\n",
        "    min_images = float('inf')\n",
        "    class_images = {}\n",
        "\n",
        "    for label, class_name in enumerate(class_labels):\n",
        "        class_dir = os.path.join(path_dir, class_name)\n",
        "        class_images[class_name] = []\n",
        "\n",
        "        if not os.path.exists(class_dir):\n",
        "            print(f\"Directory '{class_name}' not found in '{path_dir}'. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        for jpg in os.listdir(class_dir):\n",
        "            image_path = os.path.join(class_dir, jpg)\n",
        "            image_high_resolution = cv2.imread(image_path)\n",
        "\n",
        "            if image_high_resolution is None:\n",
        "                print(f\"Could not read image '{jpg}' in '{class_name}' directory. Skipping...\")\n",
        "                continue\n",
        "\n",
        "            image_change_color = cv2.cvtColor(image_high_resolution, cv2.COLOR_BGR2RGB)\n",
        "            image_low_resolution = cv2.resize(image_change_color, (256, 256))\n",
        "            class_images[class_name].append(image_low_resolution)\n",
        "            min_images = min(min_images, len(class_images[class_name]))\n",
        "        print(f\"Class '{class_name}' has {len(class_images[class_name])} images.\")\n",
        "\n",
        "    for class_name, images_list in class_images.items():\n",
        "        images.extend(images_list[:target_num_images])\n",
        "        labels.extend([class_name] * min(len(images_list), target_num_images))\n",
        "\n",
        "    return np.asarray(images), np.asarray(labels)\n",
        "\n",
        "dataset_directory = './Datasets/DataImages/'\n",
        "class_labels = ['Catla', 'Cyprinus carpio', 'Grass Carp', 'Mori', 'Rohu', 'Silver']\n",
        "target_num_images = 50\n",
        "\n",
        "# Load and preprocess data\n",
        "images, labels = load_and_process_images(dataset_directory, class_labels, target_num_images)\n",
        "\n",
        "# Split data into train and test sets\n",
        "images_train_, images_test_, labels_train_, labels_test_ = train_test_split(images, labels, test_size=0.2, random_state=42,stratify=labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW5bhhWUirGz",
        "outputId": "d2f5150d-9edc-4a36-8c2b-b4b7bc2812e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "images_train.shape (182, 256, 256, 3)\n",
            "labels_train.shape (182,)\n",
            "(182, 256, 256, 3)\n",
            "(182,)\n",
            "6\n",
            "16\n",
            "40\n",
            "9\n",
            "40\n",
            "40\n",
            "37\n",
            "pairs_train (4072, 2, 256, 256, 3)\n",
            "pairs_labels_train (4072,)\n"
          ]
        }
      ],
      "source": [
        "images_train, images_test, labels_train, labels_test = images_train_, images_test_, labels_train_, labels_test_\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "labels_train = le.fit_transform(labels_train)\n",
        "\n",
        "data_augmentation = keras.Sequential([\n",
        "\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.2),\n",
        "])\n",
        "\n",
        "def create_pairs(images, labels):\n",
        "  pairs_list, labels_list = [], []\n",
        "\n",
        "  print(images.shape)\n",
        "  print(labels.shape)\n",
        "  num_classes = len(np.unique(labels))\n",
        "  print(num_classes)\n",
        "\n",
        "  # Loop through all classes\n",
        "  for i in range(num_classes):\n",
        "    # Select indices of images belonging to class i\n",
        "    class_indices = np.where(labels == i)[0]\n",
        "    print(len(class_indices))\n",
        "    # Ensure there are at least two samples in the class\n",
        "    if len(class_indices) > 1:\n",
        "      # Create positive pairs using combinations\n",
        "      class_pairs = list(combinations(class_indices, 2))\n",
        "      pairs_list.extend([[images[i], images[j]] for i, j in class_pairs])\n",
        "      labels_list.extend([1] * len(class_pairs))  # Label positive pairs as 1\n",
        "\n",
        "      # Create negative pairs by sampling from other classes\n",
        "      for j in range(num_classes):\n",
        "        if i != j:  # Skip the same class\n",
        "          other_class_indices = np.where(labels == j)[0]\n",
        "          if len(other_class_indices) > 0:\n",
        "            # Sample random negative pairs from other class\n",
        "            random_indices = np.random.choice(other_class_indices, size=len(class_pairs))\n",
        "            negative_pairs = list(zip(class_indices, random_indices))\n",
        "            pairs_list.extend([[images[i], images[j]] for i, j in negative_pairs])\n",
        "            labels_list.extend([0] * len(negative_pairs))  # Label negative pairs as 0\n",
        "\n",
        "  return np.array(pairs_list), np.array(labels_list)\n",
        "\n",
        "\n",
        "# Create positive and negative pairs for training\n",
        "\n",
        "print('images_train.shape',images_train.shape)\n",
        "print('labels_train.shape',labels_train.shape)\n",
        "pairs_train, pairs_labels_train = create_pairs(images_train, labels_train)\n",
        "print('pairs_train',pairs_train.shape)\n",
        "print('pairs_labels_train',pairs_labels_train.shape)\n",
        "# Shuffle the training pairs\n",
        "pairs_train, pairs_labels_train = shuffle(pairs_train, pairs_labels_train, random_state=42)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "pairs_train, pairs_val, pairs_labels_train, labels_val = train_test_split(\n",
        "    pairs_train, pairs_labels_train, test_size=0.1, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(408, 256, 256, 3)\n",
            "(408, 256, 256, 3)\n",
            "(408,)\n"
          ]
        }
      ],
      "source": [
        "print(pairs_val[:,0].shape)\n",
        "print(pairs_val[:,1].shape)\n",
        "print(labels_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSo0NqJJK3eZ",
        "outputId": "e36780b1-c12b-4605-ca3d-b85b1bb0f4f6"
      },
      "outputs": [],
      "source": [
        "def create_simclr_model(base_model, input_shape):\n",
        "    inputs_1 = keras.Input(shape=input_shape, name=\"input_1\")\n",
        "    inputs_2 = keras.Input(shape=input_shape, name=\"input_2\")\n",
        "\n",
        "    x_1 = base_model(inputs_1)\n",
        "    x_2 = base_model(inputs_2)\n",
        "\n",
        "    x_1 = layers.GlobalAveragePooling2D()(x_1)\n",
        "    x_2 = layers.GlobalAveragePooling2D()(x_2)\n",
        "\n",
        "    x_1 = layers.Dense(256, activation='relu')(x_1)\n",
        "    x_2 = layers.Dense(256, activation='relu')(x_2)\n",
        "\n",
        "    x_1 = layers.Lambda(lambda x: K.l2_normalize(x, axis=1))(x_1)\n",
        "    x_2 = layers.Lambda(lambda x: K.l2_normalize(x, axis=1))(x_2)\n",
        "\n",
        "    model = Model([inputs_1, inputs_2], [x_1, x_2])\n",
        "    return model\n",
        "\n",
        "# ResNet50 is just an example; you can use ResNet150 if available\n",
        "base_model = keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "simclr_model = create_simclr_model(base_model, (256, 256, 3))\n",
        "\n",
        "def contrastive_loss(y_true, y_pred):\n",
        "    margin = 1.0\n",
        "    y_true = K.cast(y_true, 'float32')  # Cast y_true to float32\n",
        "    square_pred = K.square(y_pred[0] - y_pred[1])\n",
        "    margin_square = K.square(K.maximum(margin - square_pred, 0))\n",
        "    return K.mean(y_true * K.cast(square_pred, 'float32') + (1 - y_true) * K.cast(margin_square, 'float32'), axis=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shapes:\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "\n",
            "Validation data shapes:\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        }
      ],
      "source": [
        "print(\"Training data shapes:\")\n",
        "augmentation_train_0 = data_augmentation(pairs_train[:, 0])\n",
        "augmentation_train_1 = data_augmentation(pairs_train[:, 1])\n",
        "\n",
        "print(\"\\nValidation data shapes:\")\n",
        "augmentation_val_0 = data_augmentation(pairs_val[:, 0])\n",
        "augmentation_val_1 = data_augmentation(pairs_val[:, 1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "VfVwYXq3rEOm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "115/115 [==============================] - 486s 4s/step - loss: 1.9999 - lambda_7_loss: 1.0000 - lambda_8_loss: 1.0000 - val_loss: 1.9997 - val_lambda_7_loss: 0.9997 - val_lambda_8_loss: 1.0000\n",
            "Epoch 2/2\n",
            "115/115 [==============================] - 485s 4s/step - loss: 2.0000 - lambda_7_loss: 1.0000 - lambda_8_loss: 1.0000 - val_loss: 1.9997 - val_lambda_7_loss: 0.9997 - val_lambda_8_loss: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2b2e6968c40>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compile the model\n",
        "simclr_model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss=contrastive_loss)\n",
        "\n",
        "# Train the model\n",
        "simclr_model.fit(\n",
        "    [augmentation_train_0, augmentation_train_1],\n",
        "    [np.zeros_like(pairs_labels_train), np.zeros_like(pairs_labels_train)],\n",
        "    epochs=2,\n",
        "    batch_size=32,\n",
        "    validation_data=([augmentation_val_0, augmentation_val_1], [np.zeros_like(labels_val), np.zeros_like(labels_val)])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_5m-ZS9ttQA",
        "outputId": "03e98d4e-5b53-46c1-ac7a-1e85fa2484ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(46, 256, 256, 3)\n",
            "(46,)\n",
            "6\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "pairs_test (0,)\n",
            "pairs_labels_test (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\POOJYANTH REDDY\\AppData\\Local\\Temp\\ipykernel_22732\\2396405537.py:25: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  class_indices = np.where(labels == i)[0]\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[34], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpairs_labels_test\u001b[39m\u001b[38;5;124m'\u001b[39m,pairs_labels_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Apply data augmentation on test pairs\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m augmentation_test_0 \u001b[38;5;241m=\u001b[39m data_augmentation(\u001b[43mpairs_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      8\u001b[0m augmentation_test_1 \u001b[38;5;241m=\u001b[39m data_augmentation(pairs_test[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Predict embeddings for the test pairs\u001b[39;00m\n",
            "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
          ]
        }
      ],
      "source": [
        "# Evaluate on the test set\n",
        "pairs_test, pairs_labels_test = create_pairs(images_test, labels_test)\n",
        "print('pairs_test',pairs_test.shape)\n",
        "print('pairs_labels_test',pairs_labels_test.shape)\n",
        "\n",
        "# Apply data augmentation on test pairs\n",
        "augmentation_test_0 = data_augmentation(pairs_test[:, 0])\n",
        "augmentation_test_1 = data_augmentation(pairs_test[:, 1])\n",
        "\n",
        "# Predict embeddings for the test pairs\n",
        "embeddings_test_0, embeddings_test_1 = simclr_model.predict([augmentation_test_0, augmentation_test_1])\n",
        "\n",
        "# Calculate cosine similarity between embeddings\n",
        "cosine_similarity = np.sum(embeddings_test_0 * embeddings_test_1, axis=-1)\n",
        "\n",
        "# Threshold for considering pairs as matching\n",
        "threshold = 0.5\n",
        "\n",
        "# Predict binary labels (1 for matching pairs, 0 for non-matching pairs)\n",
        "predicted_labels = (cosine_similarity > threshold).astype(int)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(pairs_labels_test, predicted_labels)\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuesTg_gtw44",
        "outputId": "8e25f010-8d37-4a56-9062-91f48bf801e5"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"C:\\Users\\POOJYANTH REDDY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\POOJYANTH REDDY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\POOJYANTH REDDY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\POOJYANTH REDDY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\POOJYANTH REDDY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\POOJYANTH REDDY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\input_spec.py\", line 216, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model_4\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 256, 256, 3) dtype=uint8>]\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Predict the labels for test data\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43msimclr_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m predicted_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Convert predicted labels back to original class labels\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mC:\\Users\\POOJYA~1\\AppData\\Local\\Temp\\__autograph_generated_file2u5ov9bm.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\POOJYANTH REDDY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 2137, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\POOJYANTH REDDY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 2123, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\POOJYANTH REDDY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 2111, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\POOJYANTH REDDY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\training.py\", line 2079, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\POOJYANTH REDDY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\POOJYANTH REDDY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\engine\\input_spec.py\", line 216, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model_4\" expects 2 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 256, 256, 3) dtype=uint8>]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Predict the labels for test data\n",
        "predictions = simclr_model.predict(images_test)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Convert predicted labels back to original class labels\n",
        "predicted_labels_original = label_encoder.inverse_transform(predicted_labels)\n",
        "\n",
        "# Calculate and print the accuracy\n",
        "accuracy = accuracy_score(labels_test, predicted_labels_original)\n",
        "print(f'Test Accuracy: {accuracy}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
